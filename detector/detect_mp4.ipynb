{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blais\\anaconda3\\lib\\site-packages\\skimage\\io\\manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\models\\logs\n",
      "C:\\Users\\blais\\TACO-master\\TACO-master\\detector\n",
      "C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\models\\logs\n",
      "C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\models\\mask_rcnn_taco0100.h5\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import utils\n",
    "import visualize\n",
    "from visualize import display_images\n",
    "import model as modellib\n",
    "from config import Config\n",
    "from model import log\n",
    "import detector\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "\n",
    "import norfair\n",
    "from norfair import Detection, Paths, Video\n",
    "\n",
    "from typing import List\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "print(ROOT_DIR)\n",
    "MODEL_DIR=os.path.join(ROOT_DIR, \"models\\logs\")\n",
    "print(MODEL_DIR)\n",
    "COCO_MODEL_PATH=os.path.join(ROOT_DIR, \"models\\mask_rcnn_taco0100.h5\")\n",
    "print(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Number of images used: 1500\n",
      "Class Count: 11\n",
      "  0. BG                                                \n",
      "  1. Bottle                                            \n",
      "  2. Bottle cap                                        \n",
      "  3. Can                                               \n",
      "  4. Cigarette                                         \n",
      "  5. Cup                                               \n",
      "  6. Lid                                               \n",
      "  7. Other                                             \n",
      "  8. Plastic bag + wrapper                             \n",
      "  9. Pop tab                                           \n",
      " 10. Straw                                             \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import dataset\n",
    "\n",
    "# Load class map - these tables map the original TACO classes to your desired class system\n",
    "# and allow you to discard classes that you don't want to include.\n",
    "class_map = {}\n",
    "with open(\"./taco_config/map_10.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    class_map = {row[0]:row[1] for row in reader}\n",
    "\n",
    "# Load full dataset or a subset\n",
    "TACO_DIR = \"../data\"\n",
    "round = None # Split number: If None, loads full dataset else if int > 0 selects split no \n",
    "subset = \"test\" # Used only when round !=None, Options: ('train','val','test') to select respective subset\n",
    "dataset = dataset.Taco()\n",
    "taco = dataset.load_taco(TACO_DIR, round, subset, class_map=class_map, return_taco=True)\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Class Count: {}\".format(dataset.num_classes))\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask RCNN Configuration\n",
    "class TacoTestConfig(Config):\n",
    "    NAME = \"taco\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 10\n",
    "    NUM_CLASSES = dataset.num_classes\n",
    "config = TacoTestConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1944: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\model.py:348: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\model.py:408: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\model.py:433: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\model.py:740: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\model.py:742: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\model.py:816: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "C:\\Users\\blais\\TACO-master\\TACO-master\\detector\\models\\logs\n"
     ]
    }
   ],
   "source": [
    "model=modellib.MaskRCNN(mode=\"inference\", model_dir=TACO_DIR, config=config)\n",
    "print(MODEL_DIR)\n",
    "#inpath=\"./models/logs/mask_rcnn_taco_0100.h5\"\n",
    "#outpath = \"C:/Users/blais/Internship/TACO-master/TACO-master/data\"\n",
    "#outpath=\"./models/logs/mask_rcnn_taco_0100.h5\"\n",
    "model_path=\"./models/logs/mask_rcnn_taco_0100.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:175: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:180: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:184: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:193: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\blais\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:200: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model.load_weights(weights_in_path=model_path, weights_out_path=model_path,\n",
    "# by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\",\"mrcnn_mask\"])\n",
    "model.load_weights(weights_in_path=model_path, weights_out_path=model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norftrack(res):\n",
    "    norftection: List[Detection]=[]\n",
    "    for x in range (len(res['rois'])):\n",
    "        box=np.array([[res['rois'][x][1], res['rois'][x][0]], [res['rois'][x][3], res['rois'][x][2]]])\n",
    "        #box=np.array([[res['rois'][x][0], res['rois'][x][1]], [res['rois'][x][2], res['rois'][x][3]]])\n",
    "        scores=np.array([res['scores'][x], res['scores'][x]])\n",
    "        norftection.append(Detection(points=box, scores=scores))\n",
    "    return norftection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norftrack2(res):\n",
    "    norftection: List[Detection]=[]\n",
    "    for x in range(len(res['rois'])):\n",
    "        yc=(res['rois'][x][0]+res['rois'][x][2])/2\n",
    "        xc=(res['rois'][x][1]+res['rois'][x][3])/2\n",
    "        \n",
    "        centroid=np.array([xc, yc])\n",
    "        scores=np.array([res['scores'][x]])\n",
    "        norftection.append(Detection(points=centroid, scores=scores))\n",
    "        \n",
    "    return norftection\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_distance(detection, tracked_obj):\n",
    "    #print(tracked_obj.estimate)\n",
    "    return np.linalg.norm(detection.points-tracked_obj.estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_distance(detection, tracked_obj):\n",
    "    box1=np.concatenate([detection.points[0], detection.points[1]])\n",
    "    box2=np.concatenate([tracked_obj.estimate[0], tracked_obj.estimate[1]])\n",
    "    \n",
    "    #print(box1)\n",
    "    #print(box2)\n",
    "    ya=max(box1[0], box2[0])\n",
    "    xa=max(box1[1], box2[1])\n",
    "    yb=max(box1[2], box2[2])\n",
    "    xb=max(box1[3], box2[3])\n",
    "    \n",
    "    area=max(0, xb-xa+1)*max(0, yb-ya+1)\n",
    "    \n",
    "    aarea=(box1[2]-box1[0]+1)*(box1[3]-box1[1]+1)\n",
    "    barea=(box2[2]-box2[0]+1)*(box2[3]-box2[1]+1)\n",
    "    \n",
    "    iou=area/float(aarea+barea-area)\n",
    "    \n",
    "    return 1/iou if iou else (10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(pnt):\n",
    "    return[np.mean(np.array(pnt), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (720, 1280, 3)        min:    0.00000  max:  255.00000  float32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ef14f60e0f08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m#vid_img=cv.cvtColor(vid_img, cv.COLOR_BGR2RGB)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0morimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\TACO-master\\TACO-master\\detector\\model.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, images, verbose)\u001b[0m\n\u001b[0;32m   2589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2590\u001b[0m         \u001b[1;31m# Mold inputs to format expected by the neural network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2591\u001b[1;33m         \u001b[0mmolded_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmold_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2593\u001b[0m         \u001b[1;31m# Validate image sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\TACO-master\\TACO-master\\detector\\model.py\u001b[0m in \u001b[0;36mmold_inputs\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m   2484\u001b[0m                 \u001b[0mmin_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMAGE_MIN_SCALE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m                 \u001b[0mmax_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMAGE_MAX_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m                 mode=self.config.IMAGE_RESIZE_MODE)\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mmolded_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmold_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmolded_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[1;31m# Build image_meta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\TACO-master\\TACO-master\\detector\\utils.py\u001b[0m in \u001b[0;36mresize_image\u001b[1;34m(image, min_dim, max_dim, min_scale, mode)\u001b[0m\n\u001b[0;32m    490\u001b[0m         image = skimage.transform.resize(\n\u001b[0;32m    491\u001b[0m             \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m             order=1, mode=\"constant\", preserve_range=True)\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;31m# Need padding or cropping?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[0;32m    219\u001b[0m         out = warp(image, tform, output_shape=output_shape, order=order,\n\u001b[0;32m    220\u001b[0m                    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m                    preserve_range=preserve_range)\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# n-dimensional interpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py\u001b[0m in \u001b[0;36mwarp\u001b[1;34m(image, inverse_map, map_args, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[0;32m    951\u001b[0m                                                   \u001b[0moutput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m                                                   \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 953\u001b[1;33m                                                   cval=cval))\n\u001b[0m\u001b[0;32m    954\u001b[0m                 \u001b[0mwarped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# make a list to store all the frames\n",
    "vid_array = []\n",
    "# getting the video\n",
    "vid2 = cv.VideoCapture(\"../data/vid2/sample_10s.mp4\")  # the video i used is about a second long\n",
    "\n",
    "#tracker=norfair.Tracker(distance_function=key_distance, distance_threshold=3.33)\n",
    "tracker=norfair.Tracker(distance_function=euc_distance, distance_threshold=30)\n",
    "\n",
    "path=Paths(center, attenuation=0.01)\n",
    "# checks whether frames were extracted\n",
    "success = 1\n",
    "\n",
    "while success:\n",
    "    # read the frame and add it to the frame list\n",
    "    success, image = vid2.read()\n",
    "    vid_array.append(image)\n",
    "count=0\n",
    "for img in vid_array:\n",
    "    if count<(len(vid_array)-1):\n",
    "        img=cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        vid_array[count]=img\n",
    "    \n",
    "    count+=1\n",
    "# go through and detect all frames in the list  \n",
    "counter=0\n",
    "totalitems=[]\n",
    "line=400\n",
    "\n",
    "\n",
    "for vid_img in vid_array:\n",
    "    if counter<(len(vid_array)-1):\n",
    "        #vid_img=cv.cvtColor(vid_img, cv.COLOR_BGR2RGB)\n",
    "        orimage=img_to_array(vid_img)\n",
    "        results=model.detect([orimage], verbose=1)\n",
    "        r=results[0]\n",
    "        print(counter)\n",
    "        #print(r['rois'])\n",
    "        counter+=1\n",
    "        #det=norftrack(r)\n",
    "        det=norftrack2(r)\n",
    "        tracked=tracker.update(detections=det)\n",
    "\n",
    "\n",
    "\n",
    "        #norfair.draw_boxes(orimage, det)\n",
    "        norfair.draw_points(orimage, det)\n",
    "\n",
    "        #print(tracked)\n",
    "        #print(tracked)\n",
    "        itemsdet=0\n",
    "        if (counter>=7):\n",
    "            for item in tracked:\n",
    "                #print(item.id)\n",
    "                #print(item.estimate[0][1])\n",
    "                if ((line+15)>item.estimate[0][1]>(line-15)):\n",
    "                    print(\"item\", item.id, \"detected\")\n",
    "                    totalitems.append(item.id)\n",
    "            totalitems=[*set(totalitems)]\n",
    "            print(totalitems)\n",
    "\n",
    "        #norfair.draw_tracked_boxes(orimage, tracked)\n",
    "        norfair.draw_tracked_objects(orimage, tracked, color=(0, 225, 0), id_size=3, id_thickness=2)\n",
    "\n",
    "        frame=path.draw(vid_img, tracked)\n",
    "        orimage=cv.line(orimage, (0,line), (2000, line), (255, 0, 0), 6)\n",
    "\n",
    "        visualize.display_instances(orimage, r['rois'], r['masks'], r['class_ids'], dataset.class_names, r['scores'])\n",
    "        plt.close()  # close the figure after displaying it to free up memory\n",
    "print(len(totalitems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
