{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f55f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\n",
      "C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\\models\\logs\n",
      "C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\\models\\mask_rcnn_taco0100.h5\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import utils\n",
    "import visualize\n",
    "from visualize import display_images\n",
    "import model as modellib\n",
    "from config import Config\n",
    "from model import log\n",
    "import detector\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "\n",
    "import norfair\n",
    "from norfair import Detection, Paths, Tracker, Video\n",
    "\n",
    "from typing import List\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "print(ROOT_DIR)\n",
    "MODEL_DIR=os.path.join(ROOT_DIR, \"models\\logs\")\n",
    "print(MODEL_DIR)\n",
    "COCO_MODEL_PATH=os.path.join(ROOT_DIR, \"models\\mask_rcnn_taco0100.h5\")\n",
    "print(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c1b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Number of images used: 1500\n",
      "Class Count: 11\n",
      "  0. BG                                                \n",
      "  1. Bottle                                            \n",
      "  2. Bottle cap                                        \n",
      "  3. Can                                               \n",
      "  4. Cigarette                                         \n",
      "  5. Cup                                               \n",
      "  6. Lid                                               \n",
      "  7. Other                                             \n",
      "  8. Plastic bag + wrapper                             \n",
      "  9. Pop tab                                           \n",
      " 10. Straw                                             \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import dataset\n",
    "\n",
    "# Load class map - these tables map the original TACO classes to your desired class system\n",
    "# and allow you to discard classes that you don't want to include.\n",
    "class_map = {}\n",
    "with open(\"./taco_config/map_10.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    class_map = {row[0]:row[1] for row in reader}\n",
    "\n",
    "# Load full dataset or a subset\n",
    "TACO_DIR = \"../data\"\n",
    "round = None # Split number: If None, loads full dataset else if int > 0 selects split no \n",
    "subset = \"test\" # Used only when round !=None, Options: ('train','val','test') to select respective subset\n",
    "dataset = dataset.Taco()\n",
    "taco = dataset.load_taco(TACO_DIR, round, subset, class_map=class_map, return_taco=True)\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Class Count: {}\".format(dataset.num_classes))\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d962c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1944: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\\model.py:348: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\\model.py:408: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\\model.py:433: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\\model.py:740: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\\model.py:742: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\\model.py:816: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "C:\\Users\\ellen\\Documents\\Programming\\Internship\\TACO-master\\detector\\models\\logs\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:175: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:180: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:184: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:193: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\anaconda3\\envs\\taco_sb\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:200: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mask RCNN Configuration\n",
    "class TacoTestConfig(Config):\n",
    "    NAME = \"taco\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 5\n",
    "    NUM_CLASSES = dataset.num_classes\n",
    "config = TacoTestConfig()\n",
    "\n",
    "model=modellib.MaskRCNN(mode=\"inference\", model_dir=TACO_DIR, config=config)\n",
    "print(MODEL_DIR)\n",
    "#inpath=\"./models/logs/mask_rcnn_taco_0100.h5\"\n",
    "#outpath = \"C:/Users/blais/Internship/TACO-master/TACO-master/data\"\n",
    "#outpath=\"./models/logs/mask_rcnn_taco_0100.h5\"\n",
    "model_path=\"./models/logs/mask_rcnn_taco_0100.h5\"\n",
    "\n",
    "#model.load_weights(weights_in_path=model_path, weights_out_path=model_path,\n",
    "# by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\",\"mrcnn_mask\"])\n",
    "model.load_weights(weights_in_path=model_path, weights_out_path=model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "474ee65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norftrack(res,class_list):\n",
    "#res: the list of dicts returned by the model.detect function\n",
    "#class_list: the list of class ids for each detection\n",
    "\n",
    "    norftection: List[Detection]=[]\n",
    "    for x in range(len(res['rois'])):\n",
    "        yc=(res['rois'][x][0]+res['rois'][x][2])/2\n",
    "        xc=(res['rois'][x][1]+res['rois'][x][3])/2\n",
    "        \n",
    "        #the class of the particular detection\n",
    "        det_class = res['class_ids'][x] #int class ID\n",
    "        class_list.append(det_class)\n",
    "        \n",
    "        centroid=np.array([xc, yc])\n",
    "        scores=np.array([res['scores'][x]])\n",
    "        norftection.append(Detection(points=centroid, scores=scores))\n",
    "        \n",
    "    return norftection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3099f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_distance(detection, tracked_obj):\n",
    "    #print(tracked_obj.estimate)\n",
    "    return np.linalg.norm(detection.points-tracked_obj.estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58edc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_distance(detection, tracked_obj):\n",
    "    box1=np.concatenate([detection.points[0], detection.points[1]])\n",
    "    box2=np.concatenate([tracked_obj.estimate[0], tracked_obj.estimate[1]])\n",
    "    \n",
    "    #print(box1)\n",
    "    #print(box2)\n",
    "    ya=max(box1[0], box2[0])\n",
    "    xa=max(box1[1], box2[1])\n",
    "    yb=max(box1[2], box2[2])\n",
    "    xb=max(box1[3], box2[3])\n",
    "    \n",
    "    area=max(0, xb-xa+1)*max(0, yb-ya+1)\n",
    "    \n",
    "    aarea=(box1[2]-box1[0]+1)*(box1[3]-box1[1]+1)\n",
    "    barea=(box2[2]-box2[0]+1)*(box2[3]-box2[1]+1)\n",
    "    \n",
    "    iou=area/float(aarea+barea-area)\n",
    "    \n",
    "    return 1/iou if iou else (10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6444e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(pnt):\n",
    "    return[np.mean(np.array(pnt), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3044963",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# make a list to store all the frames\n",
    "vid_array = []\n",
    "# getting the video\n",
    "vid2 = cv.VideoCapture(\"../data/vid2/sample_10s.mp4\")  # the video i used is about a second long\n",
    "\n",
    "#norfair tracker\n",
    "tracker=norfair.Tracker(distance_function=euc_distance, distance_threshold=30)\n",
    "path=Paths(center, attenuation=0.01)\n",
    "\n",
    "# checks whether frames were extracted\n",
    "success = 1\n",
    "while success:\n",
    "    # read the frame and add it to the frame list\n",
    "    success, image = vid2.read()\n",
    "    vid_array.append(image)\n",
    "#color correction\n",
    "count=0\n",
    "for img in vid_array:\n",
    "    if count<(len(vid_array)-1):\n",
    "        img=cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        vid_array[count]=img\n",
    "    count+=1\n",
    "    \n",
    "# go through and detect all frames in the list  \n",
    "frame_counter=1\n",
    "line=400\n",
    "obj_class = []\n",
    "#each class is represented by a set to avoid duplication\n",
    "totalitems=set()\n",
    "bottles=set()\n",
    "botcap=set()\n",
    "cans=set()\n",
    "cigarettes=set()\n",
    "cups=set()\n",
    "lids=set()\n",
    "others=set()\n",
    "wrapperbag=set()\n",
    "poptabs=set()\n",
    "straws=set()\n",
    "#list of sets can be indexed by class_id\n",
    "setlist = [totalitems,bottles,botcap,cans,cigarettes,cups,lids,others,wrapperbag,poptabs,straws]\n",
    "\n",
    "for vid_img in vid_array:\n",
    "    if frame_counter<(len(vid_array)-1): #ignore the last image, which is blank\n",
    "        orimage=img_to_array(vid_img)\n",
    "        results=model.detect([orimage], verbose=1)\n",
    "        r=results[0]\n",
    "        print(\"Frame \" + str(frame_counter))\n",
    "        \n",
    "        #convert to norfair detection and add to tracked items\n",
    "        det=norftrack(r,obj_class)\n",
    "        tracked=tracker.update(detections=det) #list of tracked items\n",
    "        \n",
    "        norfair.draw_points(orimage, det)\n",
    "        norfair.draw_tracked_objects(orimage, tracked, color=(0, 225, 0), id_size=3, id_thickness=2)\n",
    "        \n",
    "        if (frame_counter>7):\n",
    "            x = 0\n",
    "            while x < len(tracked):\n",
    "                item = tracked[x] #specific tracked item\n",
    "                item_class = obj_class[x] #item's corresponding class id\n",
    "                if ((line+15)>item.estimate[0][1]>(line-15)): #if an object is within range of the line\n",
    "                    setlist[0].add(item.id) #add the item to the list of counted items\n",
    "                    print(\"item\", item.id, \"detected\",dataset.class_names[item_class])\n",
    "                    setlist[item_class].add(item.id) #add the item id to its class's corresponding set\n",
    "                x += 1\n",
    "            print(\"bottles\", bottles)\n",
    "            print(\"bottle caps\", botcap)\n",
    "            print(\"cans\", cans)\n",
    "            print(\"cigarettes\", cigarettes)\n",
    "            print(\"cups\", cups)\n",
    "            print(\"lids\", lids)\n",
    "            print(\"other\", others)\n",
    "            print(\"wrapper + bag\", wrapperbag)\n",
    "            print(\"pop tabs\", poptabs)\n",
    "            print(\"straws\", straws)\n",
    "            print(\"total\", totalitems)\n",
    "\n",
    "        frame=path.draw(vid_img, tracked)\n",
    "        orimage=cv.line(orimage, (0,line), (2000, line), (255, 0, 0), 6)\n",
    "\n",
    "        visualize.display_instances(orimage, r['rois'], r['masks'], r['class_ids'], dataset.class_names, r['scores'])\n",
    "        plt.close()  # close the figure after displaying it to free up memory\n",
    "        frame_counter+=1\n",
    "        \n",
    "print(\"bottles\", len(bottles))\n",
    "print(\"bottle caps\", len(botcap))\n",
    "print(\"cans\", len(cans))\n",
    "print(\"cigarettes\", len(cigarettes))\n",
    "print(\"cups\", len(cups))\n",
    "print(\"lids\", len(lids))\n",
    "print(\"other\", len(others))\n",
    "print(\"wrapper + bag\", len(wrapperbag))\n",
    "print(\"pop tabs\", len(poptabs))\n",
    "print(\"straws\", len(straws))\n",
    "print(\"total\", len(totalitems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0783b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# make a list to store all the frames\n",
    "vid_array = []\n",
    "# getting the video\n",
    "vid2 = cv.VideoCapture(\"../data/vid2/sample.mp4\")  # the video i used is about a second long\n",
    "\n",
    "#tracker=norfair.Tracker(distance_function=key_distance, distance_threshold=3.33)\n",
    "tracker=norfair.Tracker(distance_function=euc_distance, distance_threshold=30)\n",
    "\n",
    "path=Paths(center, attenuation=0.01)\n",
    "# checks whether frames were extracted\n",
    "success = 1\n",
    "while success:\n",
    "    # read the frame and add it to the frame list\n",
    "    success, image = vid2.read()\n",
    "    vid_array.append(image)\n",
    "\n",
    "# go through and detect all frames in the list  \n",
    "\n",
    "for vid_img in vid_array:\n",
    "    vid_img = cv.cvtColor(vid_img, cv.COLOR_BGR2RGB)\n",
    "    orimage=img_to_array(vid_img)\n",
    "    results=model.detect([orimage], verbose=1)\n",
    "    r=results[0]\n",
    "    #convert detections to norfair, update tracker\n",
    "    det=norftrack(r)\n",
    "    tracked=tracker.update(detections=det)\n",
    "    \n",
    "    #norfair.draw_boxes(orimage, det)\n",
    "    norfair.draw_points(orimage, det)\n",
    "    \n",
    "    print(tracked)\n",
    "    #norfair.draw_tracked_boxes(orimage, tracked)\n",
    "    norfair.draw_tracked_objects(orimage, tracked, id_thickness=2)\n",
    "    \n",
    "    frame=path.draw(vid_img, tracked)\n",
    "    \n",
    "    visualize.display_instances(orimage, r['rois'], r['masks'], r['class_ids'], dataset.class_names, r['scores'])\n",
    "    plt.close()  # close the figure after displaying it to free up memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
